"""
This type stub file was generated by pyright.
"""
from __future__ import absolute_import, division, print_function, annotations
import numpy
from PIL import Image, ImageFilter

"""
Image hashing library
======================

Example:

>>> from PIL import Image
>>> import imagehash
>>> hash = imagehash.average_hash(Image.open('test.png'))
>>> print(hash)
d879f8f89b1bbf
>>> otherhash = imagehash.average_hash(Image.open('other.bmp'))
>>> print(otherhash)
ffff3720200ffff
>>> print(hash == otherhash)
False
>>> print(hash - otherhash)
36
>>> for r in range(1, 30, 5):
...     rothash = imagehash.average_hash(Image.open('test.png').rotate(r))
...     print('Rotation by %d: %d Hamming difference' % (r, hash - rothash))
...
Rotation by 1: 2 Hamming difference
Rotation by 6: 11 Hamming difference
Rotation by 11: 13 Hamming difference
Rotation by 16: 17 Hamming difference
Rotation by 21: 19 Hamming difference
Rotation by 26: 21 Hamming difference
>>>
"""
__version__ = ...


class ImageHash:
    """
    Hash encapsulation. Can be used for dictionary keys and comparisons.
    """

    def __init__(self, binary_array) -> None:
        ...

    def __str__(self) -> str:
        ...

    def __repr__(self) -> str:
        ...

    def __sub__(self, other: ImageHash) -> int:
        ...

    def __eq__(self, other: ImageHash) -> bool:
        ...

    def __ne__(self, other: ImageHash) -> bool:
        ...

    def __hash__(self) -> int:
        ...

    def __len__(self) -> int:
        ...


def hex_to_hash(hexstr) -> ImageHash:
    """
    Convert a stored hash (hex, as retrieved from str(Imagehash))
    back to a Imagehash object.

    Notes:
    1. This algorithm assumes all hashes are either
       bidimensional arrays with dimensions hash_size * hash_size,
       or onedimensional arrays with dimensions binbits * 14.
    2. This algorithm does not work for hash_size < 2.
    """
    ...


def hex_to_flathash(hexstr, hashsize) -> ImageHash:
    ...


def old_hex_to_hash(hexstr, hash_size=...) -> ImageHash:
    """
    Convert a stored hash (hex, as retrieved from str(Imagehash))
    back to a Imagehash object. This method should be used for
    hashes generated by ImageHash up to version 3.7. For hashes
    generated by newer versions of ImageHash, hex_to_hash should
    be used instead.
    """
    ...


def average_hash(image, hash_size=..., mean=...) -> ImageHash:
    """
    Average Hash computation

    Implementation follows http://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html

    Step by step explanation: https://web.archive.org/web/20171112054354/https://www.safaribooksonline.com/blog/2013/11/26/image-hashing-with-python/

    @image must be a PIL instance.
    @mean how to determine the average luminescence. can try numpy.median instead.
    """
    ...


def phash(image: Image.Image, hash_size: int = ..., highfreq_factor: int = ...) -> ImageHash:
    """
    Perceptual Hash computation.

    Implementation follows http://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html

    @image must be a PIL instance.
    """
    ...


def phash_simple(image, hash_size=..., highfreq_factor=...) -> ImageHash:
    """
    Perceptual Hash computation.

    Implementation follows http://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html

    @image must be a PIL instance.
    """
    ...


def dhash(image, hash_size=...) -> ImageHash:
    """
    Difference Hash computation.

    following http://www.hackerfactor.com/blog/index.php?/archives/529-Kind-of-Like-That.html

    computes differences horizontally

    @image must be a PIL instance.
    """
    ...


def dhash_vertical(image, hash_size=...) -> ImageHash:
    """
    Difference Hash computation.

    following http://www.hackerfactor.com/blog/index.php?/archives/529-Kind-of-Like-That.html

    computes differences vertically

    @image must be a PIL instance.
    """
    ...


def whash(image, hash_size=..., image_scale=..., mode=..., remove_max_haar_ll=...) -> ImageHash:
    """
    Wavelet Hash computation.

    based on https://www.kaggle.com/c/avito-duplicate-ads-detection/

    @image must be a PIL instance.
    @hash_size must be a power of 2 and less than @image_scale.
    @image_scale must be power of 2 and less than image size. By default is equal to max
            power of 2 for an input image.
    @mode (see modes in pywt library):
            'haar' - Haar wavelets, by default
            'db4' - Daubechies wavelets
    @remove_max_haar_ll - remove the lowest low level (LL) frequency using Haar wavelet.
    """
    ...


def colorhash(image, binbits=...) -> ImageHash:
    """
    Color Hash computation.

    Computes fractions of image in intensity, hue and saturation bins:

    * the first binbits encode the black fraction of the image
    * the next binbits encode the gray fraction of the remaining image (low saturation)
    * the next 6*binbits encode the fraction in 6 bins of saturation, for highly saturated parts of the remaining image
    * the next 6*binbits encode the fraction in 6 bins of saturation, for mildly saturated parts of the remaining image

    @binbits number of bits to use to encode each pixel fractions
    """
    ...


class ImageMultiHash:
    """
    This is an image hash containing a list of individual hashes for segments of the image.
    The matching logic is implemented as described in Efficient Cropping-Resistant Robust Image Hashing
    """

    def __init__(self, hashes) -> None:
        ...

    def __eq__(self, other) -> bool:
        ...

    def __ne__(self, other) -> bool:
        ...

    def __sub__(self, other, hamming_cutoff=..., bit_error_rate=...) -> int | float:
        ...

    def __hash__(self) -> int:
        ...

    def __str__(self) -> str:
        ...

    def __repr__(self) -> str:
        ...

    def hash_diff(self, other_hash, hamming_cutoff=..., bit_error_rate=...) -> tuple[int, Unknown | int]:
        """
        Gets the difference between two multi-hashes, as a tuple. The first element of the tuple is the number of
        matching segments, and the second element is the sum of the hamming distances of matching hashes.
        NOTE: Do not order directly by this tuple, as higher is better for matches, and worse for hamming cutoff.
        :param other_hash: The image multi hash to compare against
        :param hamming_cutoff: The maximum hamming distance to a region hash in the target hash
        :param bit_error_rate: Percentage of bits which can be incorrect, an alternative to the hamming cutoff. The
        default of 0.25 means that the segment hashes can be up to 25% different
        """
        ...

    def matches(self, other_hash, region_cutoff=..., hamming_cutoff=..., bit_error_rate=...):
        """
        Checks whether this hash matches another crop resistant hash, `other_hash`.
        :param other_hash: The image multi hash to compare against
        :param region_cutoff: The minimum number of regions which must have a matching hash
        :param hamming_cutoff: The maximum hamming distance to a region hash in the target hash
        :param bit_error_rate: Percentage of bits which can be incorrect, an alternative to the hamming cutoff. The
        default of 0.25 means that the segment hashes can be up to 25% different
        """
        ...

    def best_match(self, other_hashes, hamming_cutoff=..., bit_error_rate=...):
        """
        Returns the hash in a list which is the best match to the current hash
        :param other_hashes: A list of image multi hashes to compare against
        :param hamming_cutoff: The maximum hamming distance to a region hash in the target hash
        :param bit_error_rate: Percentage of bits which can be incorrect, an alternative to the hamming cutoff.
        Defaults to 0.25 if unset, which means the hash can be 25% different
        """
        ...


def crop_resistant_hash(image, hash_func=..., limit_segments=..., segment_threshold=..., min_segment_size=..., segmentation_image_size=...) -> ImageMultiHash:
    """
    Creates a CropResistantHash object, by the algorithm described in the paper "Efficient Cropping-Resistant Robust
    Image Hashing". DOI 10.1109/ARES.2014.85
    This algorithm partitions the image into bright and dark segments, using a watershed-like algorithm, and then does
    an image hash on each segment. This makes the image much more resistant to cropping than other algorithms, with
    the paper claiming resistance to up to 50% cropping, while most other algorithms stop at about 5% cropping.

    Note: Slightly different segmentations are produced when using pillow version 6 vs. >=7, due to a change in
    rounding in the greyscale conversion. This leads to a slightly different result.
    :param image: The image to hash
    :param hash_func: The hashing function to use
    :param limit_segments: If you have storage requirements, you can limit to hashing only the M largest segments
    :param segment_threshold: Brightness threshold between hills and valleys. This should be static, putting it between
    peak and trough dynamically breaks the matching
    :param min_segment_size: Minimum number of pixels for a hashable segment
    :param segmentation_image_size: Size which the image is resized to before segmentation
    """
    ...
